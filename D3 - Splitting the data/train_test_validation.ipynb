{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7DaysOfCode - Machine Learning \n",
    "\n",
    "## Day-2: Data Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing is a crucial step in the Machine Learning workflow as it ensures the quality of our data. This step involves cleaning, organizing, and transforming raw data into high-quality data that can be used to train models. Properly preprocessed data directly impacts the ability of our models to learn and make accurate predictions.\n",
    "\n",
    "Some of the data preprocessing steps, such as handling null values and duplicates, were already addressed earlier in this documentation. In this step, I will focus on enriching the dataset, standardization, and checking for multicollinearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = pd.read_csv(\"C:/Users/SAMSUNG/OneDrive/Documentos/GitHub/7DaysOfCode_SpotifyML/data/day_one.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89740, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the binary class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I am dealing with a binary classification problem, where the goal is to predict whether a song will be popular or not, I need to encode the 'popularity' column as the target variable. I have chosen a threshold of 70, which means that songs with a popularity score above 70 will be considered popular and encoded as 1, while those with a score below this threshold will be considered not popular and encoded as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target value: popularity\n",
    "spotify_df['popularity'] = spotify_df['popularity'].apply(lambda x: 1 if x > 70 else 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Feature engineering is the process of creating new featurs or transforming existing features in a dataset to improve the perfomance of machine learning models. In this step I will remove irrelevant columns and create new features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1</td>\n",
       "      <td>3.844433</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>0</td>\n",
       "      <td>2.493500</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>0</td>\n",
       "      <td>3.513767</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>1</td>\n",
       "      <td>3.365550</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>1</td>\n",
       "      <td>3.314217</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                 artists  \\\n",
       "0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  duration_ms  explicit  \\\n",
       "0                      Comedy           1     3.844433     False   \n",
       "1            Ghost - Acoustic           0     2.493500     False   \n",
       "2              To Begin Again           0     3.513767     False   \n",
       "3  Can't Help Falling In Love           1     3.365550     False   \n",
       "4                     Hold On           1     3.314217     False   \n",
       "\n",
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.676  0.4610    1    -6.746     0       0.1430        0.0322   \n",
       "1         0.420  0.1660    1   -17.235     1       0.0763        0.9240   \n",
       "2         0.438  0.3590    0    -9.734     1       0.0557        0.2100   \n",
       "3         0.266  0.0596    0   -18.515     1       0.0363        0.9050   \n",
       "4         0.618  0.4430    2    -9.681     1       0.0526        0.4690   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature track_genre  \n",
       "0          0.000001    0.3580    0.715   87.917               4    acoustic  \n",
       "1          0.000006    0.1010    0.267   77.489               4    acoustic  \n",
       "2          0.000000    0.1170    0.120   76.332               4    acoustic  \n",
       "3          0.000071    0.1320    0.143  181.740               3    acoustic  \n",
       "4          0.000000    0.0829    0.167  119.949               4    acoustic  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this initial stage,  I will be working exclusively with numeric data in this dataset. I have chosen to exclude categorical variables for some reasons:\n",
    "\n",
    "i. Limited contribution to model performance: Variables such as track_id, album_name, and track_name are unlikely to significantly improve the performance of the model, as they may not contain meaningful numerical information for the model to learn from.\n",
    "\n",
    "ii. High cardinality of variables: Variables like genre and artist may have a large number of unique categories, which can result in increased computational overhead and additional data cleaning steps. Considering the potential gains in model performance, dealing with these variables may be time-consuming and cumbersome.\n",
    "\n",
    "By excluding these categorical variables, I can streamline the data preparation process and focus on working with numerical data, which may be more relevant for the specific modeling task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = spotify_df.drop(columns = ['track_id', 'album_name', 'track_name', 'artists', 'track_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.844433</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.493500</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.513767</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.365550</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.314217</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3.570667</td>\n",
       "      <td>False</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>6</td>\n",
       "      <td>-8.807</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>98.017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>3.823333</td>\n",
       "      <td>False</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.822</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>141.284</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>4.049100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.4440</td>\n",
       "      <td>11</td>\n",
       "      <td>-9.331</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.5590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>150.960</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3.160217</td>\n",
       "      <td>False</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.4140</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>130.088</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>3.426567</td>\n",
       "      <td>False</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.6320</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.4260</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>78.899</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  duration_ms  explicit  danceability  energy  key  loudness  \\\n",
       "0           1     3.844433     False         0.676  0.4610    1    -6.746   \n",
       "1           0     2.493500     False         0.420  0.1660    1   -17.235   \n",
       "2           0     3.513767     False         0.438  0.3590    0    -9.734   \n",
       "3           1     3.365550     False         0.266  0.0596    0   -18.515   \n",
       "4           1     3.314217     False         0.618  0.4430    2    -9.681   \n",
       "5           0     3.570667     False         0.688  0.4810    6    -8.807   \n",
       "6           1     3.823333     False         0.407  0.1470    2    -8.822   \n",
       "7           1     4.049100     False         0.703  0.4440   11    -9.331   \n",
       "8           1     3.160217     False         0.625  0.4140    0    -8.700   \n",
       "9           0     3.426567     False         0.442  0.6320    1    -6.770   \n",
       "\n",
       "   mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "0     0       0.1430        0.0322          0.000001    0.3580   0.7150   \n",
       "1     1       0.0763        0.9240          0.000006    0.1010   0.2670   \n",
       "2     1       0.0557        0.2100          0.000000    0.1170   0.1200   \n",
       "3     1       0.0363        0.9050          0.000071    0.1320   0.1430   \n",
       "4     1       0.0526        0.4690          0.000000    0.0829   0.1670   \n",
       "5     1       0.1050        0.2890          0.000000    0.1890   0.6660   \n",
       "6     1       0.0355        0.8570          0.000003    0.0913   0.0765   \n",
       "7     1       0.0417        0.5590          0.000000    0.0973   0.7120   \n",
       "8     1       0.0369        0.2940          0.000000    0.1510   0.6690   \n",
       "9     1       0.0295        0.4260          0.004190    0.0735   0.1960   \n",
       "\n",
       "     tempo  time_signature  \n",
       "0   87.917               4  \n",
       "1   77.489               4  \n",
       "2   76.332               4  \n",
       "3  181.740               3  \n",
       "4  119.949               4  \n",
       "5   98.017               4  \n",
       "6  141.284               3  \n",
       "7  150.960               4  \n",
       "8  130.088               4  \n",
       "9   78.899               4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot enconding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling categorical data is a critical step in the machine learning workflow. Even though I have excluded categorical data with high cardinality, there are still some remaining variables that need to be addressed. Certain machine learning models are unable to work with categorical data directly, and it's important to avoid misinterpretation of categorical variables as continuous ones, such as interpreting key as an integer variable when it is actually a categorical variable. To address this, I will be utilizing One Hot Encoding to appropriately represent these categorical variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(df, column, prefix):\n",
    "    df = df.copy()\n",
    "    dummies = pd.get_dummies(df[column], prefix=prefix, drop_first=True) # Drop the first column to avoid multicollinearity\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop(column, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the dumies\n",
    "spotify_df = onehot_encode(spotify_df, 'mode', 'mode')\n",
    "spotify_df = onehot_encode(spotify_df, 'explicit', 'isExplicit')\n",
    "spotify_df = onehot_encode(spotify_df, 'key', 'key')\n",
    "spotify_df = onehot_encode(spotify_df, 'time_signature', 'time_signature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89740, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>mode_1</th>\n",
       "      <th>isExplicit_True</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>key_11</th>\n",
       "      <th>time_signature_1</th>\n",
       "      <th>time_signature_3</th>\n",
       "      <th>time_signature_4</th>\n",
       "      <th>time_signature_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.844433</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.493500</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.513767</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.365550</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.314217</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  duration_ms  danceability  energy  loudness  speechiness  \\\n",
       "0           1     3.844433         0.676  0.4610    -6.746       0.1430   \n",
       "1           0     2.493500         0.420  0.1660   -17.235       0.0763   \n",
       "2           0     3.513767         0.438  0.3590    -9.734       0.0557   \n",
       "3           1     3.365550         0.266  0.0596   -18.515       0.0363   \n",
       "4           1     3.314217         0.618  0.4430    -9.681       0.0526   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  mode_1  \\\n",
       "0        0.0322          0.000001    0.3580    0.715   87.917       0   \n",
       "1        0.9240          0.000006    0.1010    0.267   77.489       1   \n",
       "2        0.2100          0.000000    0.1170    0.120   76.332       1   \n",
       "3        0.9050          0.000071    0.1320    0.143  181.740       1   \n",
       "4        0.4690          0.000000    0.0829    0.167  119.949       1   \n",
       "\n",
       "   isExplicit_True  key_1  key_2  key_3  key_4  key_5  key_6  key_7  key_8  \\\n",
       "0                0      1      0      0      0      0      0      0      0   \n",
       "1                0      1      0      0      0      0      0      0      0   \n",
       "2                0      0      0      0      0      0      0      0      0   \n",
       "3                0      0      0      0      0      0      0      0      0   \n",
       "4                0      0      1      0      0      0      0      0      0   \n",
       "\n",
       "   key_9  key_10  key_11  time_signature_1  time_signature_3  \\\n",
       "0      0       0       0                 0                 0   \n",
       "1      0       0       0                 0                 0   \n",
       "2      0       0       0                 0                 0   \n",
       "3      0       0       0                 0                 1   \n",
       "4      0       0       0                 0                 0   \n",
       "\n",
       "   time_signature_4  time_signature_5  \n",
       "0                 1                 0  \n",
       "1                 1                 0  \n",
       "2                 1                 0  \n",
       "3                 0                 0  \n",
       "4                 1                 0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Scaling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I will perform standardization. Standardization involves transforming the values of the dataset such that the mean of the values is 0 and the standard deviation is 1. This is crucial because many machine learning models, including those that use the gradient descent algorithm, are sensitive to the scale of the input features. Having columns with different scales can result in issues such as overshooting or loss of computational efficiency. Standardization helps to mitigate these problems and ensures that the data is normalized to a common scale, making it more suitable for machine learning model training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['popularity', 'duration_ms', 'danceability', 'energy', 'loudness',\n",
       "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
       "       'valence', 'tempo', 'mode_1', 'isExplicit_True', 'key_1', 'key_2',\n",
       "       'key_3', 'key_4', 'key_5', 'key_6', 'key_7', 'key_8', 'key_9', 'key_10',\n",
       "       'key_11', 'time_signature_1', 'time_signature_3', 'time_signature_4',\n",
       "       'time_signature_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = spotify_df.loc[:, 'popularity']\n",
    "X = spotify_df.drop('popularity', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardization\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day-3: Train Test Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, my focus is on splitting the dataset into train, test, and validation sets. In machine learning, we split the data into train and test sets to allow our model to learn from the patterns in the training data. Once the learning is done, the model can then make predictions on unseen data from the test set. This helps us evaluate how well the model can generalize to new, unseen data and assess its performance.This step is important to avoid issues with overfitting or underfitting, which can negatively impact the model's ability to generalize to new data and result in lower accuracy.\n",
    "\n",
    "A common practice is to allocate around 80% of the data for training and 20% for testing. This is the approach I will be using to split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89740\n",
      "89740\n"
     ]
    }
   ],
   "source": [
    "print(len(X_std))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.969545\n",
       "1    0.030455\n",
       "Name: popularity, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state = 42, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One potential drawback of simply splitting the dataset into train/test sets is that the splitting may not be random, which can lead to issues with overfitting. To address this concern, I will be performing a cross-validation step. Cross-validation involves creating multiple train/test sets by splitting the data into k subsets, and training the model on k-1 of these subsets. There are various cross-validation methods available, and for this exercise, I will be using the StratifiedKFold method.\n",
    "\n",
    "The `StratifiedKFold` method is particularly useful as it ensures that the class proportions within each fold are as close as possible to the real class proportions in the overall dataset. By using cross-validation, we can obtain a more robust assessment of our model's performance and ensure that it can generalize well to unseen data, improving its reliability for real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of StratifiedKFold with the desired number of splits\n",
    "skf = StratifiedKFold(n_splits= 5, shuffle= True, random_state= 42)\n",
    "\n",
    "# Iterate over the splits and perform cross-validation\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.reset_index(drop=True)[train_index], y_train.reset_index(drop=True)[val_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
